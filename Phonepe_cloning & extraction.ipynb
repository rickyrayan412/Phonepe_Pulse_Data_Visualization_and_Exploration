{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39cb99cc-6193-4d6a-9767-8015f37bbbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de54b7e5-8343-4937-b180-cf209a56d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggre_insurance\n",
    "path1=\"C:/Users/Admin/Downloads/GUVI_Python/PhonePe_Pluse/Phone_Pe/pulse/data/aggregated/insurance/country/india/state/\"\n",
    "agg_insur_list= os.listdir(path1)\n",
    "\n",
    "columns1= {\"States\":[], \"Years\":[], \"Quarter\":[], \"Insurance_type\":[], \"Insurance_count\":[],\"Insurance_amount\":[]}\n",
    "\n",
    "for state in agg_insur_list:\n",
    "    cur_states = os.path.join(path1, state)\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            with open(cur_file, \"r\") as data_file:\n",
    "                A = json.load(data_file)\n",
    "\n",
    "            for i in A[\"data\"][\"transactionData\"]:\n",
    "                name = i[\"name\"]\n",
    "                count = i[\"paymentInstruments\"][0][\"count\"]\n",
    "                amount = i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                columns1[\"Insurance_type\"].append(name)\n",
    "                columns1[\"Insurance_count\"].append(count)\n",
    "                columns1[\"Insurance_amount\"].append(amount)\n",
    "                columns1[\"States\"].append(state)\n",
    "                columns1[\"Years\"].append(year)\n",
    "                columns1[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "aggre_insurance = pd.DataFrame(columns1)\n",
    "\n",
    "aggre_insurance[\"States\"] = aggre_insurance[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "aggre_insurance[\"States\"] = aggre_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_insurance[\"States\"] = aggre_insurance[\"States\"].str.title()\n",
    "aggre_insurance['States'] = aggre_insurance['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "\n",
    "#aggre_transaction\n",
    "path2 = \"C:/Users/Admin/Downloads/GUVI_Python/PhonePe_Pluse/Phone_Pe/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "agg_tran_list = os.listdir(path2)\n",
    "\n",
    "columns2 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Transaction_type\": [], \"Transaction_count\": [], \"Transaction_amount\": []}\n",
    "\n",
    "for state in agg_tran_list:\n",
    "    cur_states = os.path.join(path2, state)\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            with open(cur_file, \"r\") as data_file:\n",
    "                B = json.load(data_file)\n",
    "\n",
    "            for i in B[\"data\"][\"transactionData\"]:\n",
    "                name = i[\"name\"]\n",
    "                count = i[\"paymentInstruments\"][0][\"count\"]\n",
    "                amount = i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                columns2[\"Transaction_type\"].append(name)\n",
    "                columns2[\"Transaction_count\"].append(count)\n",
    "                columns2[\"Transaction_amount\"].append(amount)\n",
    "                columns2[\"States\"].append(state)\n",
    "                columns2[\"Years\"].append(year)\n",
    "                columns2[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "aggre_transaction=pd.DataFrame(columns2)\n",
    "\n",
    "aggre_transaction[\"States\"] = aggre_transaction[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "aggre_transaction[\"States\"] = aggre_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_transaction[\"States\"] = aggre_transaction[\"States\"].str.title()\n",
    "aggre_transaction['States'] = aggre_transaction['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "#aggre_user\n",
    "path3=\"C:/Users/Admin/Downloads/GUVI_Python/PhonePe_Pluse/Phone_Pe/pulse/data/aggregated/user/country/india/state/\"\n",
    "agg_user_list = os.listdir(path3)\n",
    "\n",
    "columns3 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Brands\":[],\"Transaction_count\":[], \"Percentage\":[]}\n",
    "\n",
    "for state in agg_tran_list:\n",
    "    cur_states = os.path.join(path3, state)\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            with open(cur_file, \"r\") as data_file:\n",
    "                C = json.load(data_file)\n",
    "\n",
    "            try:\n",
    "\n",
    "                for i in C[\"data\"][\"usersByDevice\"]:\n",
    "                    brand = i[\"brand\"]\n",
    "                    count = i[\"count\"]\n",
    "                    percentage = i[\"percentage\"]\n",
    "                    columns3[\"Brands\"].append(brand)\n",
    "                    columns3[\"Transaction_count\"].append(count)\n",
    "                    columns3[\"Percentage\"].append(percentage)\n",
    "                    columns3[\"States\"].append(state)\n",
    "                    columns3[\"Years\"].append(year)\n",
    "                    columns3[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "aggre_user=pd.DataFrame(columns3)\n",
    "\n",
    "aggre_user[\"States\"] = aggre_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "aggre_user[\"States\"] = aggre_user[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_user[\"States\"] = aggre_user[\"States\"].str.title()\n",
    "aggre_user['States'] = aggre_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "#map_insurance\n",
    "path4=\"C:/Users/Admin/Downloads/GUVI_Python/PhonePe_Pluse/Phone_Pe/pulse/data/map/insurance/hover/country/india/state/\"\n",
    "map_insur_list= os.listdir(path4)\n",
    "\n",
    "columns4= {\"States\":[], \"Years\":[], \"Quarter\":[], \"Districts\":[], \"Transaction_count\":[],\"Transaction_amount\":[] }\n",
    "\n",
    "for state in map_insur_list:\n",
    "    cur_states = os.path.join(path4, state)\n",
    "    map_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in map_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        map_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in map_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            with open(cur_file, \"r\") as data_file:\n",
    "                D = json.load(data_file)\n",
    "\n",
    "                for i in D[\"data\"][\"hoverDataList\"]:\n",
    "                    name = i[\"name\"]\n",
    "                    count = i[\"metric\"][0][\"count\"]\n",
    "                    amount = i[\"metric\"][0][\"amount\"]\n",
    "                    columns4[\"Districts\"].append(name)\n",
    "                    columns4[\"Transaction_count\"].append(count)\n",
    "                    columns4[\"Transaction_amount\"].append(amount)\n",
    "                    columns4[\"States\"].append(state)\n",
    "                    columns4[\"Years\"].append(year)\n",
    "                    columns4[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "map_insurance = pd.DataFrame(columns4)\n",
    "\n",
    "map_insurance[\"States\"] = map_insurance[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_insurance[\"States\"] = map_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "map_insurance[\"States\"] = map_insurance[\"States\"].str.title()\n",
    "map_insurance['States'] = map_insurance['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "#map_transaction\n",
    "path5=\"C:/Users/Admin/Downloads/GUVI_Python/PhonePe_Pluse/Phone_Pe/pulse/data/map/transaction/hover/country/india/state/\"\n",
    "map_tran_list= os.listdir(path5)\n",
    "\n",
    "columns5 = {\"States\":[], \"Years\":[], \"Quarter\":[],\"District\":[], \"Transaction_count\":[],\"Transaction_amount\":[]}\n",
    "\n",
    "\n",
    "for state in map_tran_list:\n",
    "    cur_states = os.path.join(path5, state)\n",
    "    map_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in map_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        map_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in map_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            with open(cur_file, \"r\") as data_file:\n",
    "                E = json.load(data_file)\n",
    "\n",
    "                for i in E['data'][\"hoverDataList\"]:\n",
    "                    name = i[\"name\"]\n",
    "                    count = i[\"metric\"][0][\"count\"]\n",
    "                    amount = i[\"metric\"][0][\"amount\"]\n",
    "                    columns5[\"District\"].append(name)\n",
    "                    columns5[\"Transaction_count\"].append(count)\n",
    "                    columns5[\"Transaction_amount\"].append(amount)\n",
    "                    columns5[\"States\"].append(state)\n",
    "                    columns5[\"Years\"].append(year)\n",
    "                    columns5[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "map_transaction = pd.DataFrame(columns5)\n",
    "\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.title()\n",
    "map_transaction['States'] = map_transaction['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "#map_user\n",
    "path6=\"C:/Users/Admin/Downloads/GUVI_Python/PhonePe_Pluse/Phone_Pe/pulse/data/map/user/hover/country/india/state/\"\n",
    "map_user_list= os.listdir(path6)\n",
    "\n",
    "columns6 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Districts\":[], \"RegisteredUser\":[], \"AppOpens\":[]}\n",
    "\n",
    "\n",
    "for state in map_user_list:\n",
    "    cur_states = os.path.join(path6, state)\n",
    "    map_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in map_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        map_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in map_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            with open(cur_file, \"r\") as data_file:\n",
    "                F = json.load(data_file)\n",
    "\n",
    "                for i in F[\"data\"][\"hoverData\"].items():\n",
    "                    district = i[0]\n",
    "                    registereduser = i[1][\"registeredUsers\"]\n",
    "                    appopens = i[1][\"appOpens\"]\n",
    "                    columns6[\"Districts\"].append(district)\n",
    "                    columns6[\"RegisteredUser\"].append(registereduser)\n",
    "                    columns6[\"AppOpens\"].append(appopens)\n",
    "                    columns6[\"States\"].append(state)\n",
    "                    columns6[\"Years\"].append(year)\n",
    "                    columns6[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "map_user = pd.DataFrame(columns6)\n",
    "\n",
    "map_user[\"States\"] = map_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_user[\"States\"] = map_user[\"States\"].str.replace(\"-\",\" \")\n",
    "map_user[\"States\"] = map_user[\"States\"].str.title()\n",
    "map_user['States'] = map_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "#top_insurance\n",
    "path7 = \"C:/Users/Admin/Downloads/GUVI_Python/PhonePe_Pluse/Phone_Pe/pulse/data/top/insurance/country/india/state/\"\n",
    "top_insur_list = os.listdir(path7)\n",
    "\n",
    "columns7 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Pincodes\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in top_insur_list:\n",
    "    cur_states = os.path.join(path7, state)\n",
    "    top_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in top_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        top_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in top_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            with open(cur_file, \"r\") as data_file:\n",
    "                G = json.load(data_file)\n",
    "\n",
    "                for i in G[\"data\"][\"pincodes\"]:\n",
    "                    entityName = i[\"entityName\"]\n",
    "                    count = i[\"metric\"][\"count\"]\n",
    "                    amount = i[\"metric\"][\"amount\"]\n",
    "                    columns7[\"Pincodes\"].append(entityName)\n",
    "                    columns7[\"Transaction_count\"].append(count)\n",
    "                    columns7[\"Transaction_amount\"].append(amount)\n",
    "                    columns7[\"States\"].append(state)\n",
    "                    columns7[\"Years\"].append(year)\n",
    "                    columns7[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "top_insurance = pd.DataFrame(columns7)\n",
    "\n",
    "top_insurance[\"States\"] = top_insurance[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "top_insurance[\"States\"] = top_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "top_insurance[\"States\"] = top_insurance[\"States\"].str.title()\n",
    "top_insurance['States'] = top_insurance['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "#top_transaction\n",
    "path8 = \"C:/Users/Admin/Downloads/GUVI_Python/PhonePe_Pluse/Phone_Pe/pulse/data/top/transaction/country/india/state/\"\n",
    "top_tran_list = os.listdir(path8)\n",
    "\n",
    "columns8 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Pincodes\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in top_tran_list:\n",
    "    cur_states = os.path.join(path8, state)\n",
    "    top_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in top_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        top_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in top_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            with open(cur_file, \"r\") as data_file:\n",
    "                H = json.load(data_file)\n",
    "\n",
    "                for i in H[\"data\"][\"pincodes\"]:\n",
    "                    entityName = i[\"entityName\"]\n",
    "                    count = i[\"metric\"][\"count\"]\n",
    "                    amount = i[\"metric\"][\"amount\"]\n",
    "                    columns8[\"Pincodes\"].append(entityName)\n",
    "                    columns8[\"Transaction_count\"].append(count)\n",
    "                    columns8[\"Transaction_amount\"].append(amount)\n",
    "                    columns8[\"States\"].append(state)\n",
    "                    columns8[\"Years\"].append(year)\n",
    "                    columns8[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "top_transaction = pd.DataFrame(columns8)\n",
    "\n",
    "top_transaction[\"States\"] = top_transaction[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "top_transaction[\"States\"] = top_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "top_transaction[\"States\"] = top_transaction[\"States\"].str.title()\n",
    "top_transaction['States'] = top_transaction['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "\n",
    "#top_user\n",
    "path9 = \"C:/Users/Admin/Downloads/GUVI_Python/PhonePe_Pluse/Phone_Pe/pulse/data/top/user/country/india/state/\"\n",
    "top_user_list = os.listdir(path9)\n",
    "\n",
    "columns9 = {\"States\":[], \"Years\":[], \"Quarter\":[], \"Pincodes\":[], \"RegisteredUser\":[]}\n",
    "\n",
    "for state in top_user_list:\n",
    "    cur_states = os.path.join(path9, state)\n",
    "    top_year_list = os.listdir(cur_states)\n",
    "\n",
    "    for year in top_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        top_file_list = os.listdir(cur_year)\n",
    "\n",
    "        for file in top_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)\n",
    "            with open(cur_file, \"r\") as data_file:\n",
    "                I = json.load(data_file)\n",
    "\n",
    "                for i in I[\"data\"][\"pincodes\"]:\n",
    "                    name = i[\"name\"]\n",
    "                    registeredusers = i[\"registeredUsers\"]\n",
    "                    columns9[\"Pincodes\"].append(name)\n",
    "                    columns9[\"RegisteredUser\"].append(registereduser)\n",
    "                    columns9[\"States\"].append(state)\n",
    "                    columns9[\"Years\"].append(year)\n",
    "                    columns9[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "top_user = pd.DataFrame(columns9)\n",
    "\n",
    "top_user[\"States\"] = top_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "top_user[\"States\"] = top_user[\"States\"].str.replace(\"-\",\" \")\n",
    "top_user[\"States\"] = top_user[\"States\"].str.title()\n",
    "top_user['States'] = top_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63b615f8-293a-4e0f-89ed-03d2dd271e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['andaman-&-nicobar-islands',\n",
       " 'andhra-pradesh',\n",
       " 'arunachal-pradesh',\n",
       " 'assam',\n",
       " 'bihar',\n",
       " 'chandigarh',\n",
       " 'chhattisgarh',\n",
       " 'dadra-&-nagar-haveli-&-daman-&-diu',\n",
       " 'delhi',\n",
       " 'goa',\n",
       " 'gujarat',\n",
       " 'haryana',\n",
       " 'himachal-pradesh',\n",
       " 'jammu-&-kashmir',\n",
       " 'jharkhand',\n",
       " 'karnataka',\n",
       " 'kerala',\n",
       " 'ladakh',\n",
       " 'lakshadweep',\n",
       " 'madhya-pradesh',\n",
       " 'maharashtra',\n",
       " 'manipur',\n",
       " 'meghalaya',\n",
       " 'mizoram',\n",
       " 'nagaland',\n",
       " 'odisha',\n",
       " 'puducherry',\n",
       " 'punjab',\n",
       " 'rajasthan',\n",
       " 'sikkim',\n",
       " 'tamil-nadu',\n",
       " 'telangana',\n",
       " 'tripura',\n",
       " 'uttar-pradesh',\n",
       " 'uttarakhand',\n",
       " 'west-bengal']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bce8c76-b03f-496e-98df-05774d08f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table Creation\n",
    "#sql connection\n",
    "mydb = psycopg2.connect(host = \"localhost\",\n",
    "                        user = \"postgres\",\n",
    "                        password = \"ricky412\",\n",
    "                        database = \"phonepe_data\",\n",
    "                        port = \"5432\")\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "#aggregated insurance table\n",
    "drop_query = \"drop table if exists aggregated_insurance\"\n",
    "cursor.execute(drop_query)\n",
    "mydb.commit()\n",
    "\n",
    "create_query1= '''CREATE TABLE if not exists aggregated_insurance (States varchar(50),\n",
    "                                                                      Years int,\n",
    "                                                                      Quarter int,\n",
    "                                                                      Insurance_type varchar(50),\n",
    "                                                                      Insurance_count bigint,\n",
    "                                                                      Insurance_amount bigint\n",
    "                                                                      )'''\n",
    "cursor.execute(create_query1)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in aggre_insurance.iterrows():\n",
    "    insert_query1 = '''INSERT INTO aggregated_insurance (States, Years, Quarter, Insurance_type, Insurance_count, Insurance_amount)\n",
    "                                                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "    values = (row[\"States\"],\n",
    "              row[\"Years\"],\n",
    "              row[\"Quarter\"],\n",
    "              row[\"Insurance_type\"],\n",
    "              row[\"Insurance_count\"],\n",
    "              row[\"Insurance_amount\"]\n",
    "              )\n",
    "    cursor.execute(insert_query1,values)\n",
    "    mydb.commit()\n",
    "\n",
    "\n",
    "#aggregated transaction table\n",
    "drop_query = \"drop table if exists aggregated_transaction\"\n",
    "cursor.execute(drop_query)\n",
    "mydb.commit()\n",
    "\n",
    "create_query2 = '''CREATE TABLE if not exists aggregated_transaction (States varchar(50),\n",
    "                                                                      Years int,\n",
    "                                                                      Quarter int,\n",
    "                                                                      Transaction_type varchar(50),\n",
    "                                                                      Transaction_count bigint,\n",
    "                                                                      Transaction_amount bigint\n",
    "                                                                      )'''\n",
    "cursor.execute(create_query2)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in aggre_transaction.iterrows():\n",
    "    insert_query2 = '''INSERT INTO aggregated_transaction (States, Years, Quarter, Transaction_type, Transaction_count, Transaction_amount)\n",
    "                                                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "    values = (row[\"States\"],\n",
    "              row[\"Years\"],\n",
    "              row[\"Quarter\"],\n",
    "              row[\"Transaction_type\"],\n",
    "              row[\"Transaction_count\"],\n",
    "              row[\"Transaction_amount\"]\n",
    "              )\n",
    "    cursor.execute(insert_query2,values)\n",
    "    mydb.commit()\n",
    "\n",
    "#aggregated user table\n",
    "drop_query = \"drop table if exists aggregated_user\"\n",
    "cursor.execute(drop_query)\n",
    "mydb.commit()\n",
    "\n",
    "create_query3 = '''CREATE TABLE if not exists aggregated_user (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarter int,\n",
    "                                                                Brands varchar(50),\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Percentage float)'''\n",
    "cursor.execute(create_query3)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in aggre_user.iterrows():\n",
    "    insert_query3 = '''INSERT INTO aggregated_user (States, Years, Quarter, Brands, Transaction_count, Percentage)\n",
    "                                                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "    values = (row[\"States\"],\n",
    "              row[\"Years\"],\n",
    "              row[\"Quarter\"],\n",
    "              row[\"Brands\"],\n",
    "              row[\"Transaction_count\"],\n",
    "              row[\"Percentage\"])\n",
    "    cursor.execute(insert_query3,values)\n",
    "    mydb.commit()\n",
    "\n",
    "#map_insurance_table\n",
    "drop_query = \"drop table if exists map_insurance\"\n",
    "cursor.execute(drop_query)\n",
    "mydb.commit()\n",
    "\n",
    "create_query4 = '''CREATE TABLE if not exists map_insurance (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarter int,\n",
    "                                                                District varchar(50),\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount float)'''\n",
    "cursor.execute(create_query4)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in map_insurance.iterrows():\n",
    "            insert_query4 = '''\n",
    "                INSERT INTO map_insurance (States, Years, Quarter, District, Transaction_count, Transaction_amount)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)\n",
    "\n",
    "            '''\n",
    "            values = (\n",
    "                row['States'],\n",
    "                row['Years'],\n",
    "                row['Quarter'],\n",
    "                row['Districts'],\n",
    "                row['Transaction_count'],\n",
    "                row['Transaction_amount']\n",
    "            )\n",
    "            cursor.execute(insert_query4,values)\n",
    "            mydb.commit()\n",
    "\n",
    "\n",
    "#map_transaction_table\n",
    "drop_query = \"drop table if exists map_transaction\"\n",
    "cursor.execute(drop_query)\n",
    "mydb.commit()\n",
    "\n",
    "create_query5 = '''CREATE TABLE if not exists map_transaction (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarter int,\n",
    "                                                                District varchar(50),\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount float)'''\n",
    "cursor.execute(create_query5)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in map_transaction.iterrows():\n",
    "            insert_query5 = '''\n",
    "                INSERT INTO map_transaction (States, Years, Quarter, District, Transaction_count, Transaction_amount)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)\n",
    "\n",
    "            '''\n",
    "            values = (\n",
    "                row['States'],\n",
    "                row['Years'],\n",
    "                row['Quarter'],\n",
    "                row['District'],\n",
    "                row['Transaction_count'],\n",
    "                row['Transaction_amount']\n",
    "            )\n",
    "            cursor.execute(insert_query5,values)\n",
    "            mydb.commit() \n",
    "\n",
    "\n",
    "#map_user_table\n",
    "drop_query = \"drop table if exists map_user\"\n",
    "cursor.execute(drop_query)\n",
    "mydb.commit()\n",
    "\n",
    "create_query6 = '''CREATE TABLE if not exists map_user (States varchar(50),\n",
    "                                                        Years int,\n",
    "                                                        Quarter int,\n",
    "                                                        Districts varchar(50),\n",
    "                                                        RegisteredUser bigint,\n",
    "                                                        AppOpens bigint)'''\n",
    "cursor.execute(create_query6)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in map_user.iterrows():\n",
    "    insert_query6 = '''INSERT INTO map_user (States, Years, Quarter, Districts, RegisteredUser, AppOpens)\n",
    "                        values(%s,%s,%s,%s,%s,%s)'''\n",
    "    values = (row[\"States\"],\n",
    "              row[\"Years\"],\n",
    "              row[\"Quarter\"],\n",
    "              row[\"Districts\"],\n",
    "              row[\"RegisteredUser\"],\n",
    "              row[\"AppOpens\"])\n",
    "    cursor.execute(insert_query6,values)\n",
    "    mydb.commit()\n",
    "\n",
    "#top_insurance_table\n",
    "drop_query = \"drop table if exists top_insurance\"\n",
    "cursor.execute(drop_query)\n",
    "mydb.commit()\n",
    "\n",
    "create_query7 = '''CREATE TABLE if not exists top_insurance (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarter int,\n",
    "                                                                Pincodes int,\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount bigint)'''\n",
    "cursor.execute(create_query7)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in top_insurance.iterrows():\n",
    "    insert_query7 = '''INSERT INTO top_insurance (States, Years, Quarter, Pincodes, Transaction_count, Transaction_amount)\n",
    "                                                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "    values = (row[\"States\"],\n",
    "              row[\"Years\"],\n",
    "              row[\"Quarter\"],\n",
    "              row[\"Pincodes\"],\n",
    "              row[\"Transaction_count\"],\n",
    "              row[\"Transaction_amount\"])\n",
    "    cursor.execute(insert_query7,values)\n",
    "    mydb.commit()\n",
    "\n",
    "#top_transaction_table\n",
    "drop_query = \"drop table if exists top_transaction\"\n",
    "cursor.execute(drop_query)\n",
    "mydb.commit()\n",
    "\n",
    "create_query8 = '''CREATE TABLE if not exists top_transaction (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarter int,\n",
    "                                                                pincodes int,\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount bigint)'''\n",
    "cursor.execute(create_query8)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in top_transaction.iterrows():\n",
    "    insert_query8 = '''INSERT INTO top_transaction (States, Years, Quarter, Pincodes, Transaction_count, Transaction_amount)\n",
    "                                                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "    values = (row[\"States\"],\n",
    "              row[\"Years\"],\n",
    "              row[\"Quarter\"],\n",
    "              row[\"Pincodes\"],\n",
    "              row[\"Transaction_count\"],\n",
    "              row[\"Transaction_amount\"])\n",
    "    cursor.execute(insert_query8,values)\n",
    "    mydb.commit()\n",
    "\n",
    "#top_user_table\n",
    "drop_query = \"drop table if exists top_user\"\n",
    "cursor.execute(drop_query)\n",
    "mydb.commit()\n",
    "\n",
    "create_query9 = '''CREATE TABLE if not exists top_user (States varchar(50),\n",
    "                                                        Years int,\n",
    "                                                        Quarter int,\n",
    "                                                        Pincodes int,\n",
    "                                                        RegisteredUser bigint\n",
    "                                                        )'''\n",
    "cursor.execute(create_query9)\n",
    "mydb.commit()\n",
    "\n",
    "for index,row in top_user.iterrows():\n",
    "    insert_query9 = '''INSERT INTO top_user (States, Years, Quarter, Pincodes, RegisteredUser)\n",
    "                                            values(%s,%s,%s,%s,%s)'''\n",
    "    values = (row[\"States\"],\n",
    "              row[\"Years\"],\n",
    "              row[\"Quarter\"],\n",
    "              row[\"Pincodes\"],\n",
    "              row[\"RegisteredUser\"])\n",
    "    cursor.execute(insert_query9,values)\n",
    "    mydb.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03965a2-723c-4a62-9269-5ead2fe1ad72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
